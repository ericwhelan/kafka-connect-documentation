======================
KinesisSourceConnector
======================

.. image:: KinesisSourceConnector.svg


The KinesisSourceConnector is a :term:`Source Connector`_ that is used to pull data from Amazon Kinesis in realtime and persist the data to a Kafka topic.



-------------
Configuration
-------------

.. csv-table:: Configuration
    :header: "Name", "Type", "Importance", "Default Value", "Validator", "Documentation"
    :widths: auto

    "aws.access.key.id","String","High","","","aws.access.key.id"
    "aws.secret.key.id","Password","High","","","aws.secret.key.id"
    "kafka.topic","String","High","","","The kafka topic to write the data to."
    "kinesis.stream","String","High","","","The Kinesis stream to read from."
    "kinesis.shard.id","String","High",".*","","The shard of the Kinesis stream to read from. This is a regex which can be used to read all of the shards in the stream."
    "kinesis.empty.records.backoff.ms","Long","Medium","5000","[500,...,2147483647]","The number of milliseconds to backoff when the stream is empty."
    "kinesis.position","String","Medium","TRIM_HORIZON","ValidEnum{enum=ShardIteratorType, allowed=[AT_SEQUENCE_NUMBER, AFTER_SEQUENCE_NUMBER, TRIM_HORIZON, LATEST, AT_TIMESTAMP]}","The position in the stream to reset to if no offsets are stored."
    "kinesis.record.limit","Int","Medium","500","[1,...,10000]","The number of records to read in each poll of the Kinesis shard."
    "kinesis.region","String","Medium","US_EAST_1","ValidEnum{enum=Regions, allowed=[GovCloud, US_EAST_1, US_EAST_2, US_WEST_1, US_WEST_2, EU_WEST_1, EU_WEST_2, EU_CENTRAL_1, AP_SOUTH_1, AP_SOUTHEAST_1, AP_SOUTHEAST_2, AP_NORTHEAST_1, AP_NORTHEAST_2, SA_EAST_1, CN_NORTH_1, CA_CENTRAL_1]}","The AWS region for the Kinesis stream."
    "kinesis.throughput.exceeded.backoff.ms","Long","Medium","10000","[500,...,2147483647]","The number of milliseconds to backoff when a throughput exceeded exception is thrown."


^^^^^^^^^^^^^^^^^^^^^^
Property based example
^^^^^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `standalone mode
<http://docs.confluent.io/current/connect/concepts.html#standalone-workers>`_.

.. code-block:: properties

    name=connector1
    tasks.max=1
    connector.class=com.github.jcustenborder.kafka.connect.kinesis.KinesisSourceConnector
    # The following values must be configured.
    aws.access.key.id=
    aws.secret.key.id=
    kafka.topic=
    kinesis.stream=



^^^^^^^^^^^^^^^^^^
Rest based example
^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `distributed mode
<http://docs.confluent.io/current/connect/concepts.html#distributed-workers>`_.
Write the following json to `connector.json`, configure all of the required values, and use the command below to
post the configuration to one the distributed connect worker(s).

.. code-block:: json

    {
        "name": "connector1",
        "config": {
            "connector.class": "com.github.jcustenborder.kafka.connect.kinesis.KinesisSourceConnector",
            "aws.access.key.id":"",
            "aws.secret.key.id":"",
            "kafka.topic":"",
            "kinesis.stream":"",
        }
    }

Use curl to post the configuration to one of the Kafka Connect Workers. Change `http://localhost:8083/` the the endpoint of
one of your Kafka Connect worker(s).

.. code-block:: bash

    curl -s -X POST -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors



